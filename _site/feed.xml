<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-02-02T20:34:20-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Harshita Chadha</title><subtitle>Aspiring Data Professional | MS in CS @ George Washington University</subtitle><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><entry><title type="html">Navigating London with Ease: The CLIPS-Powered Tube Navigation Expert System</title><link href="http://localhost:4000/posts/2023/12/ailondon/" rel="alternate" type="text/html" title="Navigating London with Ease: The CLIPS-Powered Tube Navigation Expert System" /><published>2023-12-20T00:00:00-08:00</published><updated>2023-12-20T00:00:00-08:00</updated><id>http://localhost:4000/posts/2023/12/ailondon</id><content type="html" xml:base="http://localhost:4000/posts/2023/12/ailondon/">&lt;blockquote&gt;
  &lt;p&gt;This blogpost showcases the abstract section from the final project report I wrote for a graduate level Rule-based Artificial Intelligence course. The full report can be found &lt;a href=&quot;/files/clips_report.pdf&quot; target=&quot;_blank&quot;&gt;here.&lt;/a&gt; GitHub repository housing the code can be found &lt;a href=&quot;https://github.com/harshitaachadha/London-Tube-Navigation-Expert-System&quot; target=&quot;_blank&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&quot;text-align: justify;&quot;&gt;
London&apos;s iconic Tube system is a marvel of urban transportation, connecting travelers to every nook and cranny of this vibrant city. However, navigating this extensive network can be a daunting task. That&apos;s where our expert system, powered by CLIPS (C Language Integrated Production System), comes into play. Designed to offer real-time information and user-friendly interaction, our project is redefining the way travelers experience the Tube.
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/tubemap.png&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: justify;&quot;&gt;
Our project has achieved significant success in refining the system to better serve the needs of travelers. More importantly, we&apos;ve addressed a crucial aspect of Tube navigation—station closures. Our expert system intelligently adapts to closures, providing alternative routes on-the-fly and ensuring users can confidently navigate the ever-changing landscape of London&apos;s underground network. At the heart of our system is an enhanced option-based interface, aiming to make user interaction as intuitive as the journey itself. We believe that accessing information and planning routes should be a seamless experience. The improved interface ensures that users can effortlessly engage with the expert system, allowing them to plan their journeys with simplicity and convenience. No more deciphering complex instructions—our system puts the power of Tube navigation directly into the hands of the traveler.
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: justify;&quot;&gt;
The success of our London Tube Navigation Expert System lies in the careful orchestration of templates, rules, and functions. These elements work in tandem to decipher user queries, process information, and deliver precise navigation guidance. Behind the scenes, our system is a sophisticated engine that transforms data into actionable insights, ensuring a reliable and efficient user experience. In the dynamic landscape of London&apos;s underground network, our CLIPS-powered Tube Navigation System is not just a project; it&apos;s a solution to the challenges faced by travelers every day. By leveraging the capabilities of artificial intelligence, our system is poised to revolutionize the way people explore and navigate the iconic Tube system.
&lt;/div&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="Artificial Intelligence" /><category term="Rule-based AI" /><category term="Expert System" /><summary type="html">Tech Post London Tube Navigation Rule-based Expert System built using CLIPS language. Final project developed for the graduate level Rule-based Artificial Intelligence course - CSCI 6511.</summary></entry><entry><title type="html">An Overview of Machine Learning-Based Predictions Techniques Using Dynamic Graphs</title><link href="http://localhost:4000/posts/2022/06/bdatpaper/" rel="alternate" type="text/html" title="An Overview of Machine Learning-Based Predictions Techniques Using Dynamic Graphs" /><published>2023-05-20T00:00:00-07:00</published><updated>2023-05-20T00:00:00-07:00</updated><id>http://localhost:4000/posts/2022/06/bdatpaper</id><content type="html" xml:base="http://localhost:4000/posts/2022/06/bdatpaper/">&lt;blockquote&gt;
  &lt;p&gt;This blogpost showcases the introduction section of a term paper I wrote for a graduate level big data analytics course. The full article can be found &lt;a href=&quot;/files/Chadha Harshita_Term Paper.pdf&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div style=&quot;text-align: justify;&quot;&gt;
Graphs and graph representation learning have become an increasingly popular field of research in the past few years. The number of publications on these topics, as can be seen in Figure 1, has seen a tremendous surge in the past few years - a 1522.54% increase since the year 2000[1-3]. The widespread interest in this field can be attributed to the utility of graphs and their ability to accurately model real-life scenarios. Not only are graphs useful tools in the field of data analysis where they help visualize and analyze the nature of interactions between represented actors but they have also increasingly become integral to the field of machine learning and predictive analysis[4,5]. Traditionally, machine learning models have been trained on datasets that constitute instances inherently assumed to be independent of each other. However, as the complexity of applications increases, so does that of the subjects of predictive analysis, and thus more complex representations are warranted.
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/images/bdatermp.png&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: justify;&quot;&gt;
To substantiate the above point, the example of a simple content-based recommender system can be considered. In such a system the training examples typically consist of the past behavior of the customer and each training example or customer data in the training set is assumed to be independent of another. However, if user data is modeled as a graph and the underlying assumption that each data point is independent of the other is ignored, then the interactions and similarities that exist between each user may be captured more effectively. The consequent increase in information available leads to more personalized recommendations and enhanced user experience. In fact, state-of-the-art recommendation systems such as those employed by big corporations like Netflix and Amazon make use of network graph models to personalize user experience[6,7]. Thus, it can be concluded that graphical data as an input to machine learning algorithms helps make more accurate predictions for complex real-life situations simply because more information is captured.
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: justify;&quot;&gt;
A majority of the current machine learning techniques for graphs work under the assumption that the underlying structure used to make predictions is static in nature but this is rarely true of real-life interactions [8,9]. For instance, in medical applications of machine learning, most of the captured patient data is time-variant and in fact, it is these timed variations that most often carry characterizing information. This is where dynamic graphs come into the picture. In addition to capturing the spatial information about the scenario they model, dynamic graphs also have a time component that helps capture temporal fluctuations of information. In terms of applications of dynamic graphs in predictive analysis, one way to handle this is to apply static graph machine learning techniques to time-variant graphs, however, the results obtained are more often than not sub-optimal. This warrants the need to develop dedicated frameworks capable of working with dynamic graphs. The field of the application of machine learning algorithms to dynamic graphs, however, is fairly new and most of the work focuses on extending static techniques by treating dynamic graphs as discrete time-stamped snapshots - a practice that is restrictive in nature. Only very recently techniques have started to emerge that treat dynamic graphs as continuous time entities that constantly evolve[10].
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: justify;&quot;&gt;
The objective of this term paper is to study some of the most recent machine-learning techniques that have been applied to dynamic graphs to obtain useful predictions. The paper is divided into five main sections. The present section serves as an introduction to the problem statement, this is followed by section two where a discussion of the importance of graphs to big data and analytics is done. In section three, an overview of dynamic graphs, major modeling techniques, and their areas of application has been provided. In section four, we present the latest machine learning frameworks that have been proposed for dynamic graphs and carry out a detailed discussion about graph representation learning algorithms and graph embedding strategies. Section number five serves to present the major conclusions drawn from the study undertaken and also discusses the future line of work that can be carried out in this domain.
&lt;/div&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="Machine Learning" /><category term="Graph data" /><category term="Dynamic Graphs" /><summary type="html">Tech Post Dynamic Graphs in Machine Learning: Exploring the Future of Predictive Analysis and Personalized Recommendations. Term paper written for Big Data and Analytics class - CSCI 6444.</summary></entry><entry><title type="html">An Overview of Artificial Intelligence Accelerators</title><link href="http://localhost:4000/posts/2022/06/csatpaper/" rel="alternate" type="text/html" title="An Overview of Artificial Intelligence Accelerators" /><published>2022-12-15T00:00:00-08:00</published><updated>2022-12-15T00:00:00-08:00</updated><id>http://localhost:4000/posts/2022/06/csatpaper</id><content type="html" xml:base="http://localhost:4000/posts/2022/06/csatpaper/">&lt;blockquote&gt;
  &lt;p&gt;This blogpost showcases the introduction section of a term paper I wrote for a graduate level computer architecture course. The full article can be found &lt;a href=&quot;/files/ChadhaH Term Paper CSCI6461Section12Spring2022November262022.pdf&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Artificial Intelligence is that branch of computer science that deals with the development of computer systems that emulate cognitive behavior to simulate complex abilities such as perception of vision, recognition of speech, logical deduction, reasoning, etc. The scientific work that can now be recognized as the earliest example of the demonstration of artificial intelligence fundamentals is the McCulloh and Pitts (1943) artificial neuron that characterized a formal turing complete design. Today, this technology is ubiquitous and intimately intertwined with the human experience. The salient ideas of artificial intelligence and associated fields have been here for more than 50 years. But despite the obvious utility of this technology their use only become prominent in everyday life in the past decade.&lt;/p&gt;

&lt;p&gt;This latency can be attributed, in part, to the lack of computer infrastructure equipped to deal with the massive amount of processing power required by artificial neural networks to generate useful results. Thus, while algorithmic innovations were at the center of the AI revolution, one of the most important contributors to the success of the field was the improvements in the underlying architecture capable of performing the required calculations, given algorithmic constraints. For instance, it is a widely held belief that the research work titled Alexnet as presented by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton (2017) from the University of Toronto rang in a new era for the AI community. They utilized a specialized hardware unit - the GPU to compute the neural network more time efficiently. While their algorithm itself was not revolutionary, their creation of an innovative mapping of the convolution operations set their solution apart.&lt;/p&gt;

&lt;p&gt;Hence, without the ability to learn complex data relations in a reasonable time frame - a capability imparted because of the improvement in the way the networks are computed - we would perhaps not have seen such widespread adoption of AI techniques, useful as they may be.&lt;/p&gt;

&lt;p&gt;Changing the way in which an AI algorithm is implemented makes the algorithm run more efficiently and saves time especially when it comes to massive real-life computations. An example of this can be demonstrated by taking the case of matrix multiplication - a ubiquitous operation in AI. In Figure 1 we see how using different computation methods to perform this operation can help improve processor performance.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/csatermp.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is where AI accelerators come into play. An artificial intelligence accelerator may be defined as a high-efficiency computing device that is capable of handling large-scale neural network workloads due to its specialized design and parallel processing capabilities. These are specialized hardware units present in computer systems that help speed up AI operations by virtue of the highly specific nature of their architecture.&lt;/p&gt;

&lt;p&gt;They are a special category of hardware accelerators - processors that are designed to increase the efficiency of the CPU by taking away some of the specialized task load. This helps in increasing the performance of the computer and the efficiency with which the task is executed. Hardware accelerators combine the flexibility that is afforded by the presence of general-purpose CPUs with the performance efficiency that specialized hardware offers to optimize task performance. A few examples of processors being used as AI accelerators are GPU or graphical processing units that are most adept at dealing with parallelized processing of massive amounts of data. Other devices include FPGAs or field programmable gate arrays and ASICs or application-specific integrated circuits.&lt;/p&gt;

&lt;p&gt;In this article, a comprehensive survey of the field of artificial intelligence accelerators has been undertaken. The first section highlights the pivotal role these specialized processors have played in the progress of the field of artificial intelligence. Following this, the evolution of computer processors and the advancements that brought about the need for the development of accelerators has been traced. Further, a detailed discussion of the major categories of AI accelerators has been conducted. The last two sections of the article present a detailed overview of the various leading industry processors that are driving innovations in the field of AI and summarise the general industry trends prevalent.&lt;/p&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="Artificial Intelligence" /><category term="Accelerators" /><category term="Computer Architecture" /><summary type="html">Tech Post From Algorithms to AI Accelerators: Unraveling the Evolution of Computer Hardware in the Age of Artificial Intelligence. Term paper written for Computer System Architecture class - CSCI 6461.</summary></entry><entry><title type="html">Modern Day Illuminati</title><link href="http://localhost:4000/posts/2022/06/moderndayilluminati/" rel="alternate" type="text/html" title="Modern Day Illuminati" /><published>2022-06-01T00:00:00-07:00</published><updated>2022-06-01T00:00:00-07:00</updated><id>http://localhost:4000/posts/2022/06/moderndayilluminati</id><content type="html" xml:base="http://localhost:4000/posts/2022/06/moderndayilluminati/">&lt;blockquote&gt;
  &lt;p&gt;View original presentation &lt;a href=&quot;/files/Modern Day Illuminati.pdf&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During my senior year of undergraduate studies, I had the opportunity to delve into the intriguing world of media houses and their impact on society. Influenced by a previous presentation on human values and society during my high school years, I embarked on a thought-provoking journey to uncover the realities of present-day media. In this blog post, we will explore the notions of control, domination, and the influence wielded by media outlets, shedding light on their potential to shape major political events and public sentiments.&lt;/p&gt;

&lt;p&gt;News media, in theory, possesses immense potential to drive economic and social improvements, especially in developing countries and emerging economies. However, the harsh reality is often far from this ideal. Rather than serving the public and acting as truth-seekers in the face of power, many media outlets have become mere mouthpieces of the influential. Their actions are characterized by the repetition of unverified rumors, the perpetuation of discrimination against minorities, and the exacerbation of societal polarization.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/illuminati.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The consequences of such media behavior extend far beyond the boundaries of the media sector itself. By failing to live up to their responsibilities, media outlets contribute to the erosion of public trust and the distortion of public opinion. The immense power they wield in shaping narratives and influencing public sentiment cannot be overlooked. This modern-day Illuminati-like influence raises questions about the ethical responsibilities of media houses and their commitment to the principles of unbiased reporting and social welfare.&lt;/p&gt;

&lt;p&gt;My presentation during the communications course shed light on the dark underbelly of present-day media houses. It served as a reminder that the media’s role in society is not to be taken lightly. As consumers of news, we must remain vigilant, question the motives behind media narratives, and demand transparency and accountability from those entrusted with delivering information. By doing so, we can foster a media landscape that genuinely serves the public interest, uplifts marginalized voices, and promotes a more informed and inclusive society.&lt;/p&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="illuminati" /><category term="media" /><category term="false news" /><summary type="html">Non-Tech Post Unmasking the Modern Day Illuminati: Exploring the powerful influence of media houses, their failure to serve the public, and the detrimental impact on society.</summary></entry><entry><title type="html">My GRE experience</title><link href="http://localhost:4000/posts/2021/01/greexperience/" rel="alternate" type="text/html" title="My GRE experience" /><published>2021-10-10T00:00:00-07:00</published><updated>2021-10-10T00:00:00-07:00</updated><id>http://localhost:4000/posts/2021/01/greexperience</id><content type="html" xml:base="http://localhost:4000/posts/2021/01/greexperience/">&lt;p&gt;Applying to graduate schools is a daunting task. Not only are you planning to sell your soul to the devil for two years (according to multiple sub Reddits), you are also committing to an extremely rigorous application process. Now, while each facet of the application is equally important for an admit, arguably one of the most apparent roadblocks amongst these are the required standardised tests. Usually, most graduate programs across the globe require some standardised test scores. Since I plan to apply to schools in North America, for me these were the IELTS and the GRE.&lt;/p&gt;

&lt;p&gt;Having studied English for almost my entire life, the IELTS was a walk in the park; the GRE? Not so much. Now admittedly since I am from an engineering background, I did not find the quantitive part of the test difficult per-say. However, I did have problems getting past the 165 mark in the beginning. Perhaps due to the nature of the test.&lt;/p&gt;

&lt;p&gt;In this article, I’ll go over the steps that I followed in order to achieve my score of 330 (162 V + 168 Q) with 4.5 in the analytical writing section.&lt;/p&gt;

&lt;h3&gt;General Overview&lt;/h3&gt;

&lt;p&gt;The graduate record examinations or the GRE is the most common standardised test that is a requirement for admissions in most non-business graduate programs. The test is typically 3.5 to 4.5 hours long depending upon your speed and constitutes six sections. The first section is analytical writing, it has two parts to it. Usually, in the first part the test taker elaborates their stance pertaining to a presented opinion. In the second task, the strength of a given line of argument is usually evaluated and points that could be stated to strengthen it further are mentioned.&lt;/p&gt;

&lt;p&gt;The next five sections are sort of a gamble. Depending upon your luck or personal opinion you either get 3 math/ quantitative and 2 verbal sections or get stuck with 3 verbal and 2 math/ quantitive sections. The extra third section, whether its verbal or quantitive, is experimental and your score there is not counted in the final result. The bad news here is that there is no way to tell which of the sections is the experimental one.&lt;/p&gt;

&lt;h3&gt;How should one go about it?&lt;/h3&gt;

&lt;p&gt;Practice, practice, and more practice. During my 5 month long preparation, I gave countless practice tests, solved tons of question banks and attended many live question solving sessions. The key is to get used to the format of the test and train your brain to sit through a 4.5 hour fiasco without completely shutting down. This is because the concepts tested in both the verbal and quantitive sections are quite basic. The ETS guys don’t really want to test you on the expanse of your vocabulary or advanced algebra. They instead want to see how efficiently you apply basic concepts to solve seemingly impossible questions. That being said, having a basic and reasonably sized GRE vocabulary and the knowledge of some sneaky math tricks do help and save a ton of time. So where does this leave one?&lt;/p&gt;

&lt;p&gt;I personally started by taking in person classes from a renowned freelancer based in India ( Write to me at harshitaachadha@gmail.com for details). However I soon realised that taking the classic “Indian approach” to this might not be a great idea. So I spent the better part of a weekend looking for online resources and found a ton of helpful material (mostly free but some paid resources as well).&lt;/p&gt;

&lt;p&gt;Magoosh is an online platform that provides GRE self paced courses. They have a lot of helpful topic relevant videos but the most useful part of their platform is the math question bank. Its computer based, timed and overall a lot similar to the actual test format. Their plans, however, are towards the costlier side. If you’re looking to get your hands on the topic explanation videos but do not really want to subscribe, I’ve got you covered. I’ll link a folder below that houses the relevant resources. The said folder also has a ton of other useful material such as book pdfs, practice tests, etc.&lt;/p&gt;

&lt;p&gt;Another online resource that turned out to be a life saver was gregmat’s material. I stumbled across Greg and his website while scouring through reddit and it was honestly the best thing that has happened to me all year. Greg has a ton of free online material both on his website and his YouTube channel. There’s tons of other useful material available with his premium subscription and before you guys run for the hills, its extremely affordable at only $5 a month.&lt;/p&gt;

&lt;p&gt;Another YouTube channel worth looking at is the tested tutor. The channel covers tons of tricky math topics and the verbal content is also quite great. Lastly and quite randomly, I stumbled across this Chinese website that, from what I could understand, is their version of reddit/ quora. In one of the forums, people post reading comprehension passages along with the answers and this can be a good practice for those of you looking for a hike in the verbal scores.&lt;/p&gt;

&lt;h3&gt;Specific Tips&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
For analytical writing, I utilised the prompts in the practice tests that I gave. To get an idea about the structuring and the tentative components of the SA, I would recommend that you refer to gregmat’s video + the tested tutor’s video on this topic. Apart from that the only advice I can give is not neglecting this section. Its the first thing that you see and if it doesn’t go well on the test day, it may end up setting a grim tone for the rest of the sections. Also, the more used to it you are, the lesser would be the brain power it consumes on the test day.
&lt;/li&gt;
&lt;li&gt;
For the quantitive section, you should have timed practice sessions. A gregmat subscription gives you access to a math question bank with difficulty labels. If you have access, then start with the easy ones and time yourself. If you do not have this subscription and prefer referring to books instead, then also time yourself. It’s the way to go. Some of the topics that are the toughest and needed most reviewing on my part were Venn diagrams, work rates, and probability combinatronics mixed problems. I referred to the tested tutor&apos;s YouTube videos for these.
&lt;/li&gt;
&lt;li&gt;
For the verbal section, in sentence completion question more important than knowing the words is discerning the context in which the blank is presented. With practice you realise that more often than not, the answers end up being simple everyday words that we overlook because we fail to recognise the context. In the multiple word selection questions, very frequently the options given are presented in pairs (this happens quite often although not every time). If you are able to recognise the synonym pairs, the question becomes a cakewalk. Two words wouldn’t match at all and out of the other two pairs left, one would be totally tone deaf leaving the correct option exposed. This technique is explained in detail on gregmat’s YouTube channel in case my rendition was messed up. In the reading comprehension questions, the task is to extract the relevant information from the passage. You have to tear away the jargon to get to the main point. Again, I referred to gregmat’s video for better strategies.
&lt;/li&gt;
&lt;li&gt;
Finally, for the vocabulary part, I think I memorised maybe 200 words specifically for the GRE. I am a firm believer in the fact that more important than mugging up words is to understand the question. However, I did have a vocabulary list and I’ll link that below along with the rest of the resources that I’ve mentioned.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that’s about it. If you found this blog post all over the pace, I apologise. I might still be quite close to the catastrophe to report on it objectively. Finally, I would like to remind you all that every person is unique with different strengths and weaknesses. This was my experience and you do not have to do everything I did to achieve your dream score. The only important thing is to find your pace and have fun!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;External Links - &lt;a href=&quot;https://magoosh.com/&quot; target=&quot;_blank&quot;&gt;Magoosh&lt;/a&gt;, &lt;a href=&quot;https://drive.google.com/drive/u/0/folders/1tIFPRS_LC7XwLgR1hT5lnbp3-PPnjdgB&quot; target=&quot;_blank&quot;&gt;G Drive Resources&lt;/a&gt;, &lt;a href=&quot;https://www.gregmat.com/&quot; target=&quot;_blank&quot;&gt;gregmat’s website&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/channel/UCktwzce9ncy_K78l1KBZkYQ&quot; target=&quot;_blank&quot;&gt;gregmat’s YouTube Chanel&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/c/TheTestedTutor&quot; target=&quot;_blank&quot;&gt;The Tested Tutor’s YouTube Channel &lt;/a&gt;, &lt;a href=&quot;https://zhuanlan.zhihu.com/p/105122499&quot; target=&quot;_blank&quot;&gt;The Chinese Website&lt;/a&gt;, and &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1edWRDm1aoWx8_r1Q8M-d9eYhVAWgDxnK6-cuHgWSUXU/edit?usp=sharing&quot; target=&quot;_blank&quot;&gt;My Vocab List&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="GRE" /><category term="IELTS" /><category term="experience" /><summary type="html">Academic Post Navigating the GRE: Strategies, Resources, and Insights for Conquering the Graduate School Admission Test.</summary></entry><entry><title type="html">Your Next Big Weekend Project</title><link href="http://localhost:4000/posts/2021/01/projectguide/" rel="alternate" type="text/html" title="Your Next Big Weekend Project" /><published>2021-01-23T00:00:00-08:00</published><updated>2021-01-23T00:00:00-08:00</updated><id>http://localhost:4000/posts/2021/01/projectguide</id><content type="html" xml:base="http://localhost:4000/posts/2021/01/projectguide/">&lt;p&gt;Starting a new project can be quite challenging, especially when you’re struggling to come up with exciting ideas that truly ignite your enthusiasm. Luckily, I’ve always had a knack for brainstorming wild and wonderful concepts. Of course, being just one person, I can’t possibly pursue every single idea that pops into my head. That’s why I decided to write this article—to provide some much-needed inspiration for those of you who are currently facing a creative block.&lt;/p&gt;

&lt;p&gt;After much deliberation, I’ve managed to compile a list of five fantastic ideas that are bound to get your creative juices flowing. Who knows, one of these ideas might just become the perfect weekend project for you. So, without further ado, let’s dive right in and explore these exciting possibilities!&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt; &lt;h3&gt;The friend debt counter &lt;/h3&gt;&lt;br /&gt;
&lt;p&gt; Now I know that money splitting apps are a dime a dozen on the app store and google play store alike but stay with me here a moment. What if instead of just splitting the funds, the app also keeps track of all the expenses you contribute when your friend group goes for an outing? I don’t know about you, but I have been in situations where I haven’t always had change to pay for my auto-rickshaw and one of my friends has swooped in to save the day. The app can help you keep track of all such little monetary nuances so that no one may call you a penny pincher the next time you decide to stop being the charity that serves cold coffees to aggrieved almost engineers. You could also maybe add a payment utility where all of your friends’ Paytm accounts can sync on one of the devices via some authentication and one account pays the establishment after collecting the split money from all accounts. Now that is stuff dreams are made of.
&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt; &lt;h3&gt;A hospital suggester &lt;/h3&gt;&lt;br /&gt;
&lt;p&gt; Now since I plan to pursue my master’s in applied machine learning, it should come as no surprise that I decided to drag my personal interests into this otherwise generic list. I came up with this idea while watching one of the wonderfully informative (insert eye roll) news channels of our country. One of the age-old arguments used by media to slander any law enforcement agency is the time delay that takes place during transportation of the victim to the hospital. This issue sadly is not just an argument but in reality, many grievances turn to fatalities due to time delays. This project works to alleviate this latency. Real-time traffic data from google maps can be accessed to take care of the choice of the optimum route. The real work is to create and integrate a utility at the end of hospitals. Each hospital may have a central system that tracks the number of empty beds in the emergency room and using Bluetooth technology, the number of available doctors at that instant. Machine learning can then be applied to make optimum hospital selection where guaranteed and quick help to the victim is provided. If this entire technology is concentrated into an application, it can be of immense use in case of accidents or medical emergencies.
&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt; &lt;h3&gt;A songwriter/Composer AI &lt;/h3&gt;&lt;br /&gt;
&lt;p&gt; This idea came to me while I was decorating my Christmas tree and was on the 3 millionth iteration of the same Christmas playlist. Since I have worked on creating AIs that can formulate fortunes/ horror stories when fed the right data, creating one that can come up with songs when fed a lyrical database shouldn’t be too difficult. The composer part may need some work. The composer section would require the model to be able to come up with a novel tune for the song that the lyricist part generates. Although it may sound pretty difficult, people have worked on this problem before. The article [here](https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/) may serve as a beginner’s introduction to creating a tune-generating AI. With both components of the project down, you can go to town with generating hundreds of songs of whatever genre you want. Just try not to get caught up in intellectual property lawsuits!
&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt; &lt;h3&gt;An app for quick CGPA reference &lt;/h3&gt;&lt;br /&gt;
&lt;p&gt; Now I can’t speak for other colleges or universities, but the lack of centralized and reliable unofficial transcript generators for IPU students is the bane of my existence. Now, some online tools can be used to get semester wise results, but sadly they are pretty rudimentary with a very non-intuitive GUI. The CGPA reference app would need to create a central database by scraping the result data from the official IPU website which will not be that difficult because it is all publicly available as pdfs. The main part would be building an intuitive GUI which can serve as a quick reference for students when they are filling an internship application for the umpteenth time. One may also consider adding a CGPA converter that converts the CGPA from a 20.0 scale to a 4.0 one for all those poor souls who want to pursue higher education abroad.
&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt; &lt;h3&gt;A portofolio website &lt;/h3&gt;&lt;br /&gt;
&lt;p&gt; Seriously Harshita? This is what you’re thinking right now, isn’t it? I know. But trust me, however overused this project idea may be, it actually is quite beneficial in the long run. If you’re an engineer like me (well almost engineer anyway) then there may come a time when you have multiple projects that you have worked upon that really highlight your unique skillset. But since the resume you create should ideally be only one page long, you can’t include all of them on there. In such cases, it’s easier to have a website where you can showcase all your projects (maybe add cool demonstrations?). You don’t have to be into web development and create everything from scratch. If you’re a machine learning person like me (oh, how I hate CSS), you can make use of online tools like WordPress and Wix to create beautiful websites in a matter of hours. That is pretty neat in anyone’s book!
&lt;/p&gt;
&lt;/li&gt;

&lt;/ol&gt;

&lt;p&gt;And there you have it! I am all out of ideas, for now anyway. If you have any follow up questions feel free to drop me an email.&lt;/p&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="projects" /><category term="ideas" /><category term="inspiration" /><summary type="html">Tech Post Unleash your creativity with these five captivating project ideas, ranging from a friend debt counter app to an AI-powered songwriter, and find the perfect inspiration to kickstart your next weekend endeavor.</summary></entry><entry><title type="html">Zoltar: The fortune telling AI</title><link href="http://localhost:4000/posts/2020/10/ZoltarAI/" rel="alternate" type="text/html" title="Zoltar: The fortune telling AI" /><published>2020-10-31T00:00:00-07:00</published><updated>2020-10-31T00:00:00-07:00</updated><id>http://localhost:4000/posts/2020/10/ZoltarAI</id><content type="html" xml:base="http://localhost:4000/posts/2020/10/ZoltarAI/">&lt;p&gt;In this blog post, I’m excited to talk about one of my project - Zoltar the AI. Zoltar is an artificial conversation entity that has the potential for both simplicity and tremendous growth. I’ll provide a brief overview of the project, its dependencies, and walk you through the main concepts involved in creating a conversational AI. Then, based on the knowledge gained, I’ll explain the technical workings of this project in detail. To conclude, I’ll share a video demonstrating a conversation I had with Zoltar. So, let’s dive right in!&lt;/p&gt;

&lt;p&gt;The Fortune Teller project, known as Zoltar, is an AI powered by a custom-made dataset created from subreddits and New York Times Horoscope Data. For simplicity, I chose to utilize Python’s NLTK package, which is well-suited for cloud-based environments. This project is completely data-driven, meaning that more data leads to better results. Now, let’s start from the beginning to understand what exactly an AI is and how it can engage in conversations without explicit programming.&lt;/p&gt;

&lt;p&gt;AI is a sub-domain of data-driven computational practices that encompasses technologies like machine learning and deep learning. Back in 1955, Marvin Minsky and John McCarthy, both pioneers of Artificial Intelligence, defined it as any task that, if performed by a human, would be considered an application of intelligence. While traditional data-driven domains like machine learning focus on learning from data and making predictions, AI aims to replicate human behavior with notable success.&lt;/p&gt;

&lt;p&gt;The fortune-telling AI uses data to comprehend sentence structure and the words provided. To delve deeper into its functioning, let’s familiarize ourselves with a few key terms:&lt;/p&gt;

&lt;p&gt;NLTK: Short for Natural Language Processing Toolkit, NLTK provides tools and functions for processing human language inputs. It is employed in various applications such as text classification, chatbots, sentiment analysis, and language translation. This is the main package used to build Zoltar.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Tokenization: Tokenization is the process of dividing large quantities of text into smaller parts called tokens. It consists of word and sentence tokenization.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Word Tokenization: This operation is accomplished using the word_tokenize() function of NLTK, which splits a sentence into individual words.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Sentence Tokenization: The sent_tokenize() module is used to obtain a list of sentences from a paragraph, enabling us to analyze average words per sentence.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stemming: Stemming is a process of linguistic normalization that reduces words to their root form or chops off derivational affixes. For instance, words like “connection,” “connected,” and “connecting” are reduced to the common word “connect.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;POS Tagging: POS tagging identifies the grammatical group of a given word and looks for relationships within the sentence, assigning a corresponding tag to each word.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Lemmatization: Lemmatization reduces words to their base form, ensuring linguistically correct lemmas. It is usually more sophisticated than stemming, as it takes into account the context of the word. For example, “better” is lemmatized to “good.”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Stop Words: Stop words are considered noise in text analysis. They are generic, repetitive, and irrelevant words that do not contribute significantly to the overall context. Removing stop words helps refine the data.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now that we have a grasp of these fundamental concepts, let’s gain a technical overview of how Zoltar operates.The first step is to collect relevant data for training the model. I sourced New York Times fortune data from Kaggle and selected subreddits as data sources. Next, sentence and word lemmatization are performed to understand the data at its basic building units.&lt;/p&gt;

&lt;p&gt;Following this, irrelevant content such as stop words and punctuation marks are removed. Sentence vectorization is then used to group the stripped sentences into a bag-of-words model.The model is now ready to take user input and generate the most appropriate response by performing cosine similarity operations.&lt;/p&gt;

&lt;p&gt;And there you have it! Your very own conversational AI, Zoltar, is now ready to hold stimulating conversations (well, not quite). To gain deeper insights into the project or try building it yourself, feel free to refer to the GitHub repository &lt;a href=&quot;https://github.com/harshitaachadha/Zoltar-The-fortune-telling-AI&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; for the code and data. As a bonus, I recorded a conversation I had with Zoltar and added some creepy music to set the ambiance. Enjoy the video!&lt;/p&gt;

&lt;!-- blank line --&gt;
&lt;figure class=&quot;video_container&quot;&gt;
  &lt;video controls=&quot;true&quot; allowfullscreen=&quot;true&quot;&gt;
    &lt;source src=&quot;/files/file.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;/video&gt;
&lt;/figure&gt;
&lt;!-- blank line --&gt;

&lt;p&gt;If you have any questions about the terms or the project itself, don’t hesitate to reach out to me. I’m also open to discussing any improvements or additions you may have in mind for Zoltar.&lt;/p&gt;

&lt;hr /&gt;</content><author><name>Harshita Chadha</name><email>harshitachadha@gwmail.gwu.edu</email></author><category term="Natural Language Processing" /><category term="Fortune Teller" /><category term="NLTK" /><summary type="html">Tech Post Discover the fascinating world of Zoltar, an artificial conversation entity. This blog post provides an overview of its creation, the underlying concepts of conversational AI, and a technical glimpse into its working, complete with a captivating video conversation.</summary></entry></feed>